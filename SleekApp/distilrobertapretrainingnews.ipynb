{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87b37b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:12:27.187950Z",
     "iopub.status.busy": "2022-06-25T23:12:27.186821Z",
     "iopub.status.idle": "2022-06-25T23:12:35.460043Z",
     "shell.execute_reply": "2022-06-25T23:12:35.459100Z"
    },
    "papermill": {
     "duration": 8.281246,
     "end_time": "2022-06-25T23:12:35.462388",
     "exception": false,
     "start_time": "2022-06-25T23:12:27.181142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, LineByLineTextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy import spatial\n",
    "import scipy\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e4bdf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:12:35.472542Z",
     "iopub.status.busy": "2022-06-25T23:12:35.471507Z",
     "iopub.status.idle": "2022-06-25T23:12:35.476594Z",
     "shell.execute_reply": "2022-06-25T23:12:35.475786Z"
    },
    "papermill": {
     "duration": 0.010602,
     "end_time": "2022-06-25T23:12:35.478309",
     "exception": false,
     "start_time": "2022-06-25T23:12:35.467707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RemoveNewLines(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24dc7ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:12:35.485421Z",
     "iopub.status.busy": "2022-06-25T23:12:35.484827Z",
     "iopub.status.idle": "2022-06-25T23:12:44.249119Z",
     "shell.execute_reply": "2022-06-25T23:12:44.248258Z"
    },
    "papermill": {
     "duration": 8.770411,
     "end_time": "2022-06-25T23:12:44.251651",
     "exception": false,
     "start_time": "2022-06-25T23:12:35.481240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data in pd.read_csv(\"../input/news-summarization/data.csv\", chunksize=100000):\n",
    "    data = data[~data[\"Content\"].isnull()]\n",
    "    data[\"Content\"] = data[\"Content\"].apply(RemoveNewLines)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28866f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:12:44.260683Z",
     "iopub.status.busy": "2022-06-25T23:12:44.260350Z",
     "iopub.status.idle": "2022-06-25T23:12:45.596519Z",
     "shell.execute_reply": "2022-06-25T23:12:45.595681Z"
    },
    "papermill": {
     "duration": 1.344375,
     "end_time": "2022-06-25T23:12:45.598970",
     "exception": false,
     "start_time": "2022-06-25T23:12:44.254595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"w\") as f:\n",
    "    for text in data[\"Content\"].values:\n",
    "        f.write(text+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce752fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:12:45.607371Z",
     "iopub.status.busy": "2022-06-25T23:12:45.606045Z",
     "iopub.status.idle": "2022-06-25T23:12:55.053187Z",
     "shell.execute_reply": "2022-06-25T23:12:55.052287Z"
    },
    "papermill": {
     "duration": 9.453261,
     "end_time": "2022-06-25T23:12:55.055428",
     "exception": false,
     "start_time": "2022-06-25T23:12:45.602167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"../input/huggingface-roberta-variants/distilroberta-base/distilroberta-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8214cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:12:55.063127Z",
     "iopub.status.busy": "2022-06-25T23:12:55.062577Z",
     "iopub.status.idle": "2022-06-25T23:17:02.198345Z",
     "shell.execute_reply": "2022-06-25T23:17:02.197432Z"
    },
    "papermill": {
     "duration": 247.417595,
     "end_time": "2022-06-25T23:17:02.476179",
     "exception": false,
     "start_time": "2022-06-25T23:12:55.058584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "dataset = LineByLineTextDataset(tokenizer=tokenizer,\n",
    "                                file_path=\"corpus.txt\",\n",
    "                                block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f2fa83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:17:02.490863Z",
     "iopub.status.busy": "2022-06-25T23:17:02.490173Z",
     "iopub.status.idle": "2022-06-25T23:17:02.495324Z",
     "shell.execute_reply": "2022-06-25T23:17:02.494628Z"
    },
    "papermill": {
     "duration": 0.017434,
     "end_time": "2022-06-25T23:17:02.497125",
     "exception": false,
     "start_time": "2022-06-25T23:17:02.479691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
    "                                                mlm=True,\n",
    "                                                mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c786b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T23:17:02.505238Z",
     "iopub.status.busy": "2022-06-25T23:17:02.504518Z",
     "iopub.status.idle": "2022-06-26T00:42:21.331775Z",
     "shell.execute_reply": "2022-06-26T00:42:21.330827Z"
    },
    "papermill": {
     "duration": 5118.834043,
     "end_time": "2022-06-26T00:42:21.333828",
     "exception": false,
     "start_time": "2022-06-25T23:17:02.499785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 100008\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7815\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7815' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7815/7815 1:25:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.666200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.621500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.611300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.592800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.558600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.513000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.502000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-200\n",
      "Configuration saved in ./checkpoint-200/config.json\n",
      "Model weights saved in ./checkpoint-200/pytorch_model.bin\n",
      "Saving model checkpoint to ./checkpoint-400\n",
      "Configuration saved in ./checkpoint-400/config.json\n",
      "Model weights saved in ./checkpoint-400/pytorch_model.bin\n",
      "Saving model checkpoint to ./checkpoint-600\n",
      "Configuration saved in ./checkpoint-600/config.json\n",
      "Model weights saved in ./checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-800\n",
      "Configuration saved in ./checkpoint-800/config.json\n",
      "Model weights saved in ./checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-1000\n",
      "Configuration saved in ./checkpoint-1000/config.json\n",
      "Model weights saved in ./checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-1200\n",
      "Configuration saved in ./checkpoint-1200/config.json\n",
      "Model weights saved in ./checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-1400\n",
      "Configuration saved in ./checkpoint-1400/config.json\n",
      "Model weights saved in ./checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-1600\n",
      "Configuration saved in ./checkpoint-1600/config.json\n",
      "Model weights saved in ./checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-1800\n",
      "Configuration saved in ./checkpoint-1800/config.json\n",
      "Model weights saved in ./checkpoint-1800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-2000\n",
      "Configuration saved in ./checkpoint-2000/config.json\n",
      "Model weights saved in ./checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-2200\n",
      "Configuration saved in ./checkpoint-2200/config.json\n",
      "Model weights saved in ./checkpoint-2200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-1800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-2400\n",
      "Configuration saved in ./checkpoint-2400/config.json\n",
      "Model weights saved in ./checkpoint-2400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-2600\n",
      "Configuration saved in ./checkpoint-2600/config.json\n",
      "Model weights saved in ./checkpoint-2600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-2200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-2800\n",
      "Configuration saved in ./checkpoint-2800/config.json\n",
      "Model weights saved in ./checkpoint-2800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-2400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-3000\n",
      "Configuration saved in ./checkpoint-3000/config.json\n",
      "Model weights saved in ./checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-2600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-3200\n",
      "Configuration saved in ./checkpoint-3200/config.json\n",
      "Model weights saved in ./checkpoint-3200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-2800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-3400\n",
      "Configuration saved in ./checkpoint-3400/config.json\n",
      "Model weights saved in ./checkpoint-3400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-3600\n",
      "Configuration saved in ./checkpoint-3600/config.json\n",
      "Model weights saved in ./checkpoint-3600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-3200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-3800\n",
      "Configuration saved in ./checkpoint-3800/config.json\n",
      "Model weights saved in ./checkpoint-3800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-3400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-4000\n",
      "Configuration saved in ./checkpoint-4000/config.json\n",
      "Model weights saved in ./checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-3600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-4200\n",
      "Configuration saved in ./checkpoint-4200/config.json\n",
      "Model weights saved in ./checkpoint-4200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-3800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-4400\n",
      "Configuration saved in ./checkpoint-4400/config.json\n",
      "Model weights saved in ./checkpoint-4400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-4600\n",
      "Configuration saved in ./checkpoint-4600/config.json\n",
      "Model weights saved in ./checkpoint-4600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-4200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-4800\n",
      "Configuration saved in ./checkpoint-4800/config.json\n",
      "Model weights saved in ./checkpoint-4800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-4400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-5000\n",
      "Configuration saved in ./checkpoint-5000/config.json\n",
      "Model weights saved in ./checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-4600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-5200\n",
      "Configuration saved in ./checkpoint-5200/config.json\n",
      "Model weights saved in ./checkpoint-5200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-4800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-5400\n",
      "Configuration saved in ./checkpoint-5400/config.json\n",
      "Model weights saved in ./checkpoint-5400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-5600\n",
      "Configuration saved in ./checkpoint-5600/config.json\n",
      "Model weights saved in ./checkpoint-5600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-5200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-5800\n",
      "Configuration saved in ./checkpoint-5800/config.json\n",
      "Model weights saved in ./checkpoint-5800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-5400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-6000\n",
      "Configuration saved in ./checkpoint-6000/config.json\n",
      "Model weights saved in ./checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-5600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-6200\n",
      "Configuration saved in ./checkpoint-6200/config.json\n",
      "Model weights saved in ./checkpoint-6200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-5800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-6400\n",
      "Configuration saved in ./checkpoint-6400/config.json\n",
      "Model weights saved in ./checkpoint-6400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-6600\n",
      "Configuration saved in ./checkpoint-6600/config.json\n",
      "Model weights saved in ./checkpoint-6600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-6200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-6800\n",
      "Configuration saved in ./checkpoint-6800/config.json\n",
      "Model weights saved in ./checkpoint-6800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-6400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-7000\n",
      "Configuration saved in ./checkpoint-7000/config.json\n",
      "Model weights saved in ./checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-6600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-7200\n",
      "Configuration saved in ./checkpoint-7200/config.json\n",
      "Model weights saved in ./checkpoint-7200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-6800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-7400\n",
      "Configuration saved in ./checkpoint-7400/config.json\n",
      "Model weights saved in ./checkpoint-7400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-7600\n",
      "Configuration saved in ./checkpoint-7600/config.json\n",
      "Model weights saved in ./checkpoint-7600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-7200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint-7800\n",
      "Configuration saved in ./checkpoint-7800/config.json\n",
      "Model weights saved in ./checkpoint-7800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint-7400] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7815, training_loss=1.5744660068153191, metrics={'train_runtime': 5118.7426, 'train_samples_per_second': 97.688, 'train_steps_per_second': 1.527, 'total_flos': 1.657905204206592e+16, 'train_loss': 1.5744660068153191, 'epoch': 5.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=64,\n",
    "        save_steps=200,\n",
    "        save_total_limit=2,\n",
    "    ),\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6357f",
   "metadata": {
    "papermill": {
     "duration": 0.012139,
     "end_time": "2022-06-26T00:42:21.359430",
     "exception": false,
     "start_time": "2022-06-26T00:42:21.347291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5406.465998,
   "end_time": "2022-06-26T00:42:25.098751",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-25T23:12:18.632753",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
